{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_file = 'user_metadata_latest.jsonl'\n",
    "info_train = []\n",
    "with open(info_file) as fp:\n",
    "    for line in fp.readlines():\n",
    "        info_train.append(json.loads(line))\n",
    "user_info_all = pd.DataFrame(info_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         BrokenPurge\n",
       "1     flyingf28327022\n",
       "2         queenofoats\n",
       "3           NewEDProg\n",
       "4        msjoannacake\n",
       "5        elamame_bean\n",
       "6             xbertyx\n",
       "7     AshleyVargas731\n",
       "8         lifeoverAna\n",
       "9     AdriennesAngels\n",
       "10       Silencing_ED\n",
       "11    AnorexiaRecover\n",
       "12     xTheCharNinjax\n",
       "13     RealityTweeter\n",
       "14    claire_santucci\n",
       "15     madison_summer\n",
       "Name: screen_name, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info_all.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False], dtype=bool), array([16]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(user_info_all.verified, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovering from anorexia. inpatient X1 .life is worth living\n",
      "\n",
      "Tweeting all things MH & positive thoughts whilst in recovery from anorexia #justkeepswimming\n",
      "\n",
      "Jumping on the bandwagon of 'tweet what you eat.' All food is vegetarian. üå±ü•ëüçìRecovering from Anorexia. 22.07.2017 üôåüôÇ\n",
      "\n",
      "New TV series seeks 16-19yr olds suffering from anorexia to take part in a groundbreaking & pioneering therapy #ED #EDWarriors #anorexia #EDrecovery #anorexic\n",
      "\n",
      "A recovering anorexic simultaneously trying to cope with divorce, parenting teenagers, Menopause and sex.\n",
      "\n",
      "recovery from anorexia nervosa,depression and anxiety because mental illness sucks\n",
      "\n",
      "Buddhist, recovering anorexic, 18yr old girl living in the UK. love yoga/zumba/weightlifting. hate my thighs. hoping to get flexible, toned, fit and lean!!!\n",
      "\n",
      "Recovering from Anorexia. Love God. Love my husband.Creator of How to Love. How to love yourself, your body, and others.\n",
      "\n",
      "22. Depression. Anxiey. BDD. Recovering Anorexic. Fighting against Ana's voice every minute of every day. I will beat her. I will be free.\n",
      "\n",
      "I am a recovering anorexic (by the grace of courage) ! I started Adrienne's Angels in an effort to spread awareness and help others struggeling!\n",
      "\n",
      "Silencing Eating Disorders was founded by an individual in recovery from anorexia and bulimia to provide support for and raise awareness of eating disorders.\n",
      "\n",
      "This is my struggle with the road to recovering from Anorexia Nervosa. I know there are other girls out there that need support just like me.\n",
      "\n",
      "Recovering from Anorexia, Bulimia, Depression and self harm, but struggling with them all. My recovery blog: http://t.co/ZbRIp9VG\n",
      "\n",
      "Journey through recovery from anorexia, depression, & anxiety\n",
      "\n",
      "Battling Anorexia and other MH problemsüåà  ‚ÄòStorms don‚Äôt last forever‚Äô üåä\n",
      "\n",
      "Recovering from Anorexia; Here for anyone who needs help. Stay strong beauties, don't be like me.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each in user_info_all[user_info_all.verified == False].description:\n",
    "    print(each)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_file = 'user_metadata_latest.jsonl'\n",
    "info_train = []\n",
    "with open(info_file) as fp:\n",
    "    for line in fp.readlines():\n",
    "        info_train.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.DataFrame(info_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = user_info[['description','statuses_count', 'screen_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_file = 'user_tweets_latest.jsonl'\n",
    "tweet_train = []\n",
    "with open(tweet_file) as fp:\n",
    "    for line in fp.readlines():\n",
    "        tweet_train.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFoundWings = tweets[tweets.tweeter_screen_name=='NewFoundWings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFoundWings.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFoundWings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from imp import reload\n",
    "import TweetPreprocessor\n",
    "reload(TweetPreprocessor)\n",
    "from TweetPreprocessor import TweetPreprocessor \n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyse_sentiment(tweeter, preprocess=False):\n",
    "    for i in range(0, tweeter.shape[0]):\n",
    "        text = tweeter.iloc[i].text\n",
    "        np_score = analyser.polarity_scores(text)\n",
    "        \n",
    "        preprocessed_text = TweetPreprocessor.pipeline(text)\n",
    "        score = analyser.polarity_scores(preprocessed_text)\n",
    "        \n",
    "        tweeter.loc[i, 'compound'] = score['compound']\n",
    "        tweeter.loc[i, 'pos'] = score['pos']\n",
    "        tweeter.loc[i, 'neg'] = score['neg']\n",
    "        tweeter.loc[i, 'neu'] = score['neu']\n",
    "        \n",
    "        tweeter.loc[i, 'compound_np'] = np_score['compound']\n",
    "        tweeter.loc[i, 'pos_np'] = np_score['pos']\n",
    "        tweeter.loc[i, 'neg_np'] = np_score['neg']\n",
    "        tweeter.loc[i, 'neu_np'] = np_score['neu']      \n",
    "    return tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users = analyse_sentiment(pd.DataFrame(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users['is_support'] = \"No\"\n",
    "analysed_users.loc[analysed_users['tweeter_screen_name'] == \"lilglacevanille\", 'is_support'] = \"Yes\"\n",
    "analysed_users.loc[analysed_users['tweeter_screen_name'] == \"ItsKalaNoY\", 'is_support'] = \"Yes\"\n",
    "analysed_users.loc[analysed_users['tweeter_screen_name'] == \"AmandaGrundle\", 'is_support'] = \"Yes\"\n",
    "analysed_users.loc[analysed_users['tweeter_screen_name'] == \"earthtoree\", 'is_support'] = \"Yes\"\n",
    "analysed_users.loc[analysed_users['tweeter_screen_name'] == \"HanBaNannz\", 'is_support'] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yays = analysed_users[analysed_users.is_support=='Yes']\n",
    "yays.reset_index(inplace=True)\n",
    "yays_i = np.random.choice(yays.shape[0],2000)\n",
    "df1 = yays.loc[yays_i]\n",
    "\n",
    "nays = analysed_users[analysed_users.is_support=='No']\n",
    "nays.reset_index(inplace=True)\n",
    "nays_i = np.random.choice(nays.shape[0],2000)\n",
    "df2 = nays.loc[nays_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[ (analysed_users['compound_np'] !=0) & (analysed_users['compound'] !=0) ][['compound_np','compound']].hist(bins=15, by=analysed_users['is_support'],figsize=(15,5), sharex=True, sharey=True)\n",
    "analysed_users[['pos_np','pos']].hist(bins=15, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n",
    "analysed_users[['neg_np','neg']].hist(bins=15, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n",
    "analysed_users[['neu_np','neu']].hist(bins=15, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(analysed_users.is_support, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[analysed_users.id==1045461843739734016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['compound', 'pos', 'neg', 'neu']\n",
    "cols_np = ['compound_np', 'pos_np', 'neg_np', 'neu_np']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[analysed_users['is_support'] =='Yes'][cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[analysed_users['is_support'] =='No'][cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[(analysed_users['is_support'] =='Yes') & (analysed_users['compound_np'] !=0) & (analysed_users['compound'] !=0) ][['compound_np','compound']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[(analysed_users['is_support'] =='No') & (analysed_users['compound_np'] !=0) & (analysed_users['compound'] !=0) ][['compound_np','compound']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectana",
   "language": "python",
   "name": "detectana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
