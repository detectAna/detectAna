{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json\n",
    "import matplotlib.pyplot as plot\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the user metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_metadata_file = 'test.json'\n",
    "# with open(user_metadata_file) as f:\n",
    "#     users = json.load(f)\n",
    "#     user_info= pd.DataFrame(users)\n",
    "\n",
    "# print(len(user_info))\n",
    "\n",
    "user_metadata_file = 'user_metadata_latest.jsonl'\n",
    "user_metadata_list = []\n",
    "with open(user_metadata_file) as fp:\n",
    "    for line in fp.readlines():\n",
    "        user_metadata_list.append(json.loads(line))\n",
    "\n",
    "user_info = pd.DataFrame(user_metadata_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns for follows_sg, follows_professional_sg, and follows_thinspo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info['follows_sg'] = None\n",
    "user_info['follows_professional_sg'] = None\n",
    "user_info['follows_thinspo'] = None\n",
    "user_info['is_anorexia_recovery'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>profile_location</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>verified</th>\n",
       "      <th>follows_sg</th>\n",
       "      <th>follows_professional_sg</th>\n",
       "      <th>follows_thinspo</th>\n",
       "      <th>is_anorexia_recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-04 14:14:01</td>\n",
       "      <td>recovering from anorexia. inpatient X1 .life i...</td>\n",
       "      <td>63</td>\n",
       "      <td>1842</td>\n",
       "      <td>536</td>\n",
       "      <td>1060558130</td>\n",
       "      <td>en</td>\n",
       "      <td>18</td>\n",
       "      <td>Wonderland</td>\n",
       "      <td>Recovery Vs Relspse</td>\n",
       "      <td>None</td>\n",
       "      <td>BrokenPurge</td>\n",
       "      <td>18326</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-13 18:37:04</td>\n",
       "      <td>Tweeting all things MH &amp; positive thoughts whi...</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>213</td>\n",
       "      <td>1017840348083650560</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>flyingfree</td>\n",
       "      <td>None</td>\n",
       "      <td>flyingf28327022</td>\n",
       "      <td>159</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-17 17:41:33</td>\n",
       "      <td>Jumping on the bandwagon of 'tweet what you ea...</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>887004356075286528</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>South West, England</td>\n",
       "      <td>Emily May</td>\n",
       "      <td>None</td>\n",
       "      <td>queenofoats</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-06 11:15:49</td>\n",
       "      <td>New TV series seeks 16-19yr olds suffering fro...</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>256</td>\n",
       "      <td>739777811964153856</td>\n",
       "      <td>en-gb</td>\n",
       "      <td>0</td>\n",
       "      <td>London, England</td>\n",
       "      <td>NewEDProg</td>\n",
       "      <td>None</td>\n",
       "      <td>NewEDProg</td>\n",
       "      <td>221</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-01 18:36:29</td>\n",
       "      <td>A recovering anorexic simultaneously trying to...</td>\n",
       "      <td>0</td>\n",
       "      <td>4397</td>\n",
       "      <td>5661</td>\n",
       "      <td>110487555</td>\n",
       "      <td>en</td>\n",
       "      <td>108</td>\n",
       "      <td>London</td>\n",
       "      <td>msjoanna cake</td>\n",
       "      <td>None</td>\n",
       "      <td>msjoannacake</td>\n",
       "      <td>3245</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                        description  \\\n",
       "0  2013-01-04 14:14:01  recovering from anorexia. inpatient X1 .life i...   \n",
       "1  2018-07-13 18:37:04  Tweeting all things MH & positive thoughts whi...   \n",
       "2  2017-07-17 17:41:33  Jumping on the bandwagon of 'tweet what you ea...   \n",
       "3  2016-06-06 11:15:49  New TV series seeks 16-19yr olds suffering fro...   \n",
       "4  2010-02-01 18:36:29  A recovering anorexic simultaneously trying to...   \n",
       "\n",
       "   favourites_count  followers_count  friends_count                   id  \\\n",
       "0                63             1842            536           1060558130   \n",
       "1                41               50            213  1017840348083650560   \n",
       "2                31               32            185   887004356075286528   \n",
       "3                 9               77            256   739777811964153856   \n",
       "4                 0             4397           5661            110487555   \n",
       "\n",
       "    lang  listed_count             location                 name  \\\n",
       "0     en            18           Wonderland  Recovery Vs Relspse   \n",
       "1     en             0                                flyingfree   \n",
       "2     en             1  South West, England            Emily May   \n",
       "3  en-gb             0      London, England            NewEDProg   \n",
       "4     en           108               London        msjoanna cake   \n",
       "\n",
       "  profile_location      screen_name  statuses_count time_zone utc_offset  \\\n",
       "0             None      BrokenPurge           18326      None       None   \n",
       "1             None  flyingf28327022             159      None       None   \n",
       "2             None      queenofoats              22      None       None   \n",
       "3             None        NewEDProg             221      None       None   \n",
       "4             None     msjoannacake            3245      None       None   \n",
       "\n",
       "   verified follows_sg follows_professional_sg follows_thinspo  \\\n",
       "0     False       None                    None            None   \n",
       "1     False       None                    None            None   \n",
       "2     False       None                    None            None   \n",
       "3     False       None                    None            None   \n",
       "4     False       None                    None            None   \n",
       "\n",
       "  is_anorexia_recovery  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather information about the number of support groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>is_thinspo</th>\n",
       "      <th>is_anorexia_recovery</th>\n",
       "      <th>professional_sg</th>\n",
       "      <th>sg</th>\n",
       "      <th>follows_thinspo</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cheers_forana</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lifeoverAna</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>Silencing_ED,EatingRecovery,loveyourbody,EDCar...</td>\n",
       "      <td>angelaegambrel,ichosetolive,HopefulRecovery,An...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BrokenPurge</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>AnorexiaDaily,Spreading_L0ve,SelfHarmWIILEnd,A...</td>\n",
       "      <td>scalesR4fish,StandStr0ng,DyingDaisy_,AwareOfSe...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xbertyx</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>True</td>\n",
       "      <td>ProjectBuddy,AgainstSuicide</td>\n",
       "      <td>EndThePain_</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Fitness enthu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flyingf28327022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name is_thinspo is_anorexia_recovery  \\\n",
       "0    cheers_forana       TRUE                False   \n",
       "1      lifeoverAna      FALSE                 True   \n",
       "2      BrokenPurge      FALSE                 True   \n",
       "3          xbertyx      FALSE                 True   \n",
       "4  flyingf28327022        NaN                  NaN   \n",
       "\n",
       "                                     professional_sg  \\\n",
       "0                                                NaN   \n",
       "1  Silencing_ED,EatingRecovery,loveyourbody,EDCar...   \n",
       "2  AnorexiaDaily,Spreading_L0ve,SelfHarmWIILEnd,A...   \n",
       "3                       ProjectBuddy,AgainstSuicide    \n",
       "4                                                NaN   \n",
       "\n",
       "                                                  sg follows_thinspo  \\\n",
       "0                                                NaN            TRUE   \n",
       "1  angelaegambrel,ichosetolive,HopefulRecovery,An...           FALSE   \n",
       "2  scalesR4fish,StandStr0ng,DyingDaisy_,AwareOfSe...            TRUE   \n",
       "3                                        EndThePain_            TRUE   \n",
       "4                                                NaN             NaN   \n",
       "\n",
       "           Notes  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3  Fitness enthu  \n",
       "4   Private user  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_groups = pd.read_csv('supportgroup.csv', header=1)\n",
    "print(len(support_groups))\n",
    "support_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# professional support groups: 102\n",
      "# non-professional support_groups: 106\n"
     ]
    }
   ],
   "source": [
    "professional_sg_set = set()\n",
    "sg_set = set()\n",
    "\n",
    "THRESHOLD = 2\n",
    "\n",
    "for i in range(len(support_groups)):\n",
    "    screen_name = support_groups.loc[i, 'screen_name']\n",
    "    \n",
    "    # can be empty\n",
    "    idx = user_info.index[user_info['screen_name'] == screen_name]\n",
    "    \n",
    "    # get professional support groups\n",
    "    professional_sg = support_groups.loc[i, 'professional_sg']\n",
    "    if not pd.isnull(professional_sg) and professional_sg is not '-':\n",
    "        sgs = list(map(lambda x: x.lower(), professional_sg.split(',')))\n",
    "        # Classify user as following professional SG if they follow >= THRESHOLD professional SG's\n",
    "        if not idx.empty:\n",
    "            user_info.at[idx, 'follows_professional_sg'] = len(sgs) >= THRESHOLD\n",
    "        professional_sg_set.update(sgs)\n",
    "    \n",
    "    # get non-professional support groups\n",
    "    sg = support_groups.loc[i, 'sg']\n",
    "    if not pd.isnull(sg) and sg is not '-':\n",
    "        sgs = list(map(lambda x: x.lower(), sg.split(',')))\n",
    "        # Classify user as following SG if they follow >= THRESHOLD SG's\n",
    "        if not idx.empty:\n",
    "            user_info.at[idx, 'follows_sg'] = len(sgs) >= THRESHOLD\n",
    "        sg_set.update(sgs)\n",
    "        \n",
    "    is_anorexia_recovery = support_groups.loc[i, 'is_anorexia_recovery']\n",
    "    if not pd.isnull(sg) and sg is not '-':\n",
    "        if not idx.empty:\n",
    "            user_info.at[idx, 'is_anorexia_recovery'] = is_anorexia_recovery == True\n",
    "    \n",
    "    follows_thinspo = support_groups.loc[i, 'follows_thinspo']\n",
    "    if not pd.isnull(sg) and sg is not '-':\n",
    "        if not idx.empty:\n",
    "            user_info.at[idx, 'follows_thinspo'] = follows_thinspo == 'TRUE'\n",
    "        sg_set.update(sgs)\n",
    "\n",
    "print(\"# professional support groups: {}\".format(len(professional_sg_set)))\n",
    "print(\"# non-professional support_groups: {}\".format(len(sg_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify the users in the users_info data frame as following professional support groups, non-professional support groups, or neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>description</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>profile_location</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>verified</th>\n",
       "      <th>follows_sg</th>\n",
       "      <th>follows_professional_sg</th>\n",
       "      <th>follows_thinspo</th>\n",
       "      <th>is_anorexia_recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-04 14:14:01</td>\n",
       "      <td>recovering from anorexia. inpatient X1 .life i...</td>\n",
       "      <td>63</td>\n",
       "      <td>1842</td>\n",
       "      <td>536</td>\n",
       "      <td>1060558130</td>\n",
       "      <td>en</td>\n",
       "      <td>18</td>\n",
       "      <td>Wonderland</td>\n",
       "      <td>Recovery Vs Relspse</td>\n",
       "      <td>None</td>\n",
       "      <td>BrokenPurge</td>\n",
       "      <td>18326</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-13 18:37:04</td>\n",
       "      <td>Tweeting all things MH &amp; positive thoughts whi...</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>213</td>\n",
       "      <td>1017840348083650560</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>flyingfree</td>\n",
       "      <td>None</td>\n",
       "      <td>flyingf28327022</td>\n",
       "      <td>159</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-17 17:41:33</td>\n",
       "      <td>Jumping on the bandwagon of 'tweet what you ea...</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>887004356075286528</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>South West, England</td>\n",
       "      <td>Emily May</td>\n",
       "      <td>None</td>\n",
       "      <td>queenofoats</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-06 11:15:49</td>\n",
       "      <td>New TV series seeks 16-19yr olds suffering fro...</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>256</td>\n",
       "      <td>739777811964153856</td>\n",
       "      <td>en-gb</td>\n",
       "      <td>0</td>\n",
       "      <td>London, England</td>\n",
       "      <td>NewEDProg</td>\n",
       "      <td>None</td>\n",
       "      <td>NewEDProg</td>\n",
       "      <td>221</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-01 18:36:29</td>\n",
       "      <td>A recovering anorexic simultaneously trying to...</td>\n",
       "      <td>0</td>\n",
       "      <td>4397</td>\n",
       "      <td>5661</td>\n",
       "      <td>110487555</td>\n",
       "      <td>en</td>\n",
       "      <td>108</td>\n",
       "      <td>London</td>\n",
       "      <td>msjoanna cake</td>\n",
       "      <td>None</td>\n",
       "      <td>msjoannacake</td>\n",
       "      <td>3245</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                        description  \\\n",
       "0  2013-01-04 14:14:01  recovering from anorexia. inpatient X1 .life i...   \n",
       "1  2018-07-13 18:37:04  Tweeting all things MH & positive thoughts whi...   \n",
       "2  2017-07-17 17:41:33  Jumping on the bandwagon of 'tweet what you ea...   \n",
       "3  2016-06-06 11:15:49  New TV series seeks 16-19yr olds suffering fro...   \n",
       "4  2010-02-01 18:36:29  A recovering anorexic simultaneously trying to...   \n",
       "\n",
       "   favourites_count  followers_count  friends_count                   id  \\\n",
       "0                63             1842            536           1060558130   \n",
       "1                41               50            213  1017840348083650560   \n",
       "2                31               32            185   887004356075286528   \n",
       "3                 9               77            256   739777811964153856   \n",
       "4                 0             4397           5661            110487555   \n",
       "\n",
       "    lang  listed_count             location                 name  \\\n",
       "0     en            18           Wonderland  Recovery Vs Relspse   \n",
       "1     en             0                                flyingfree   \n",
       "2     en             1  South West, England            Emily May   \n",
       "3  en-gb             0      London, England            NewEDProg   \n",
       "4     en           108               London        msjoanna cake   \n",
       "\n",
       "  profile_location      screen_name  statuses_count time_zone utc_offset  \\\n",
       "0             None      BrokenPurge           18326      None       None   \n",
       "1             None  flyingf28327022             159      None       None   \n",
       "2             None      queenofoats              22      None       None   \n",
       "3             None        NewEDProg             221      None       None   \n",
       "4             None     msjoannacake            3245      None       None   \n",
       "\n",
       "   verified follows_sg follows_professional_sg follows_thinspo  \\\n",
       "0     False       True                    True            True   \n",
       "1     False       None                    None            None   \n",
       "2     False       True                    True           False   \n",
       "3     False       None                    None            None   \n",
       "4     False       None                    True            None   \n",
       "\n",
       "  is_anorexia_recovery  \n",
       "0                 True  \n",
       "1                 None  \n",
       "2                 True  \n",
       "3                 None  \n",
       "4                 None  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the new columns are populated\n",
    "user_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the rows that have protected twitter accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = user_info[user_info.follows_sg.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TweetPreprocessor import TweetPreprocessor\n",
    "\n",
    "def get_support_groups_from_list(followers):\n",
    "    support_groups = []\n",
    "    for follower in followers:\n",
    "        description, verified = TweetPreprocessor.pipeline(follower['description'].lower()), follower['verified']\n",
    "        print(description)\n",
    "    return support_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'followers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-023002c25b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfriends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfollowers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mscreen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfriends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'followers'"
     ]
    }
   ],
   "source": [
    "cols = ['description', 'verified', 'friend_id', 'associated_screen_name']\n",
    "rows = []\n",
    "\n",
    "num_users = user_info.shape[0]\n",
    "\n",
    "for i in range(num_users):\n",
    "    friends = user_info.iloc[i].followers\n",
    "    screen_name = user_info.iloc[i].screen_name\n",
    "    if isinstance(friends, list):\n",
    "        print(\"{} has {} friends\".format(screen_name, len(friends)))\n",
    "        for friend in friends:\n",
    "            # only want english speaking\n",
    "            if 'en' in friend['lang']:\n",
    "                description, verified = TweetPreprocessor.pipeline(friend['description'].lower()), friend['verified']\n",
    "                rows.append([description, verified, friend['id'], screen_name])\n",
    "            \n",
    "followers_df = pd.DataFrame(rows)\n",
    "followers_df.columns = cols\n",
    "print(\"\\nFound {} friends\".format(followers_df.shape[0]))\n",
    "followers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'followers_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-dea79ba975be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n\u001b[1;32m      7\u001b[0m                                  min_df=2, stop_words='english')\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollowers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'followers_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Try some unsupervised learning to classify the users based on description\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "n_clusters = 3\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n",
    "                                 min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(followers_df.description)\n",
    "\n",
    "km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=1)\n",
    "labels = km.fit_predict(X)\n",
    "print(\"KMeans with {} clusters fit\".format(n_clusters))\n",
    "print(labels)\n",
    "assert(len(labels) == followers_df.shape[0])\n",
    "for i in range(followers_df.shape[0]):\n",
    "    followers_df.loc[i, 'class'] = labels[i]\n",
    "followers_df[['description', 'class']]\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    class_df = followers_df[followers_df['class'] == i]\n",
    "    print(\"=\" * 20, \"Class number {}: ({} users)\".format(i, class_df.shape[0]), \"=\" * 20)\n",
    "    print(class_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['followers'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0cedd18fd9fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'statuses_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'screen_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'followers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['followers'] not in index\""
     ]
    }
   ],
   "source": [
    "dump = user_info[['description','statuses_count', 'screen_name', 'followers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dump' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c723a835726e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dump' is not defined"
     ]
    }
   ],
   "source": [
    "dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Tweets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_file = 'user_tweets_latest.jsonl'\n",
    "tweet_train = []\n",
    "with open(tweet_file) as fp:\n",
    "    for line in fp.readlines():\n",
    "        tweet_train.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HanBaNannz', 'elamame_bean', 'msjoannacake', 'cheers_forana',\n",
       "       'AdriennesAngels', 'xbertyx'], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweeter_screen_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop tweets with urls because I noticed that a lot of people are putting spam tweets such as:\n",
    "\"My daily stats: 19 new followers, 5 new unfollowers via http://t.co/LYJ6IqurZF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tweets_with_urls(df):\n",
    "    num_dropped = 0\n",
    "    print(len(df))\n",
    "    for i in range(df.shape[0]):\n",
    "        urls = df.at[i, 'entities']['urls']\n",
    "        if len(urls) > 0:\n",
    "            df.drop(i, inplace=True)\n",
    "            num_dropped += 1\n",
    "    print(\"Dropped {}\".format(num_dropped))\n",
    "    df.reset_index(inplace=True)\n",
    "    print(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9076\n",
      "Dropped 2318\n",
      "6758\n"
     ]
    }
   ],
   "source": [
    "tweets = drop_tweets_with_urls(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Classify the users as having a support group or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jtsui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from imp import reload\n",
    "import TweetPreprocessor\n",
    "reload(TweetPreprocessor)\n",
    "from TweetPreprocessor import TweetPreprocessor \n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyse_sentiment(tweeter, preprocess=False):\n",
    "    for i in range(0, tweeter.shape[0]):\n",
    "        text = tweeter.iloc[i].text\n",
    "        np_score = analyser.polarity_scores(text)\n",
    "        \n",
    "        preprocessed_text = TweetPreprocessor.pipeline(text)\n",
    "        score = analyser.polarity_scores(preprocessed_text)\n",
    "        \n",
    "        tweeter.loc[i, 'processed_text'] = preprocessed_text\n",
    "        \n",
    "        tweeter.loc[i, 'compound'] = score['compound']\n",
    "        tweeter.loc[i, 'pos'] = score['pos']\n",
    "        tweeter.loc[i, 'neg'] = score['neg']\n",
    "        tweeter.loc[i, 'neu'] = score['neu']\n",
    "        \n",
    "        tweeter.loc[i, 'compound_np'] = np_score['compound']\n",
    "        tweeter.loc[i, 'pos_np'] = np_score['pos']\n",
    "        tweeter.loc[i, 'neg_np'] = np_score['neg']\n",
    "        tweeter.loc[i, 'neu_np'] = np_score['neu']      \n",
    "    return tweeter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users = analyse_sentiment(pd.DataFrame(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[['processed_text', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_string = ''\n",
    "for i in range(analysed_users.shape[0]):\n",
    "    wordcloud_string += analysed_users.iloc[i].processed_text\n",
    "\n",
    "wordcloud = WordCloud(width=4000, height=2000,max_font_size=500).generate(wordcloud_string)\n",
    "plot.figure(figsize=(15,12))\n",
    "plot.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plot.axis(\"off\")\n",
    "plot.show()\n",
    "\n",
    "wordcloud.to_file(\"wordcloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(stop_words='english')\n",
    "tfidf_result = vec.fit_transform(analysed_users.processed_text)\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "tfidf_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(tfidf_result, feature_names, top=100):\n",
    "        if feature_names is None or tfidf_result is None:\n",
    "            return\n",
    "\n",
    "        scores = zip(feature_names,\n",
    "                     np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        labels, scores = [], []\n",
    "\n",
    "        # Get the scores and labels of the top 100 tweets\n",
    "        for item in sorted_scores[:top]:\n",
    "            print(\"{0:50} Score: {1}\".format(item[0], item[1]))\n",
    "            # sns.distplot(item[1], label=item[0])\n",
    "            labels.append(item[0])\n",
    "            scores.append(item[1])\n",
    "\n",
    "        index = np.arange(len(scores))\n",
    "        plot.bar(index, scores, figure=plot.figure(figsize=(25, 10)))\n",
    "        plot.xlabel('Word', fontsize=24)\n",
    "        plot.ylabel('TFIDF Score', fontsize=24)\n",
    "        plot.xticks(index, labels, fontsize=12, rotation=90)\n",
    "        plot.title('Top {} features'.format(top))\n",
    "        plot.savefig('Top_{}'.format(top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n(tfidf_result, feature_names, top=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtsui/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA shape: \n",
      "(6758, 10)\n",
      "NMF shape: \n",
      "(6758, 10)\n",
      "LSI shape: \n",
      "(6758, 10)\n"
     ]
    }
   ],
   "source": [
    "# Topic Modeling\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_topics=num_topics, max_iter=10, learning_method='online')\n",
    "lda_Z = lda_model.fit_transform(tfidf_result)\n",
    "print('LDA shape: ')\n",
    "print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    "\n",
    "# Build a Non-Negative Matrix Factorization Model\n",
    "nmf_model = NMF(n_components=num_topics)\n",
    "nmf_Z = nmf_model.fit_transform(tfidf_result)\n",
    "print('NMF shape: ')\n",
    "print(nmf_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    "\n",
    "# Build a Latent Semantic Indexing Model\n",
    "lsi_model = TruncatedSVD(n_components=num_topics)\n",
    "lsi_Z = lsi_model.fit_transform(tfidf_result)\n",
    "print('LSI shape: ')\n",
    "print(lsi_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, top_n=10):\n",
    "        for idx, topic in enumerate(model.components_):\n",
    "            print(\"Topic %d:\" % (idx))\n",
    "            print([(vec.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the first document in the corpus looks like in different topic spaces\n",
    "print(\"LDA Model:\")\n",
    "print(\"=\" * 20)\n",
    "print_topics(lda_model)\n",
    "print(\"=\" * 20, '\\n')\n",
    "\n",
    "print(\"NMF Model:\")\n",
    "print(\"=\" * 20)\n",
    "print_topics(nmf_model)\n",
    "print(\"=\" * 20, '\\n')\n",
    "\n",
    "print(\"LSI Model:\")\n",
    "print(\"=\" * 20)\n",
    "print_topics(lsi_model)\n",
    "print(\"=\" * 20, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add \"follows_professional_sg\" and \"follows_sg\" column to analysed_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[\"follows_sg\"] = False\n",
    "t = list(user_info[user_info[\"follows_sg\"] == True][\"screen_name\"])\n",
    "analysed_users.loc[analysed_users[\"tweeter_screen_name\"].isin(t), \"follows_sg\"] = True\n",
    "\n",
    "analysed_users[\"follows_professional_sg\"] = False\n",
    "t = list(user_info[user_info[\"follows_professional_sg\"] == True][\"screen_name\"])\n",
    "analysed_users.loc[analysed_users[\"tweeter_screen_name\"].isin(t), \"follows_professional_sg\"] = True\n",
    "\n",
    "analysed_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yays = analysed_users[(analysed_users['follows_sg'] == True) | (analysed_users['follows_professional_sg'] == True)]  \n",
    "yays.reset_index(inplace=True)\n",
    "yays_i = np.random.choice(yays.shape[0],2000)\n",
    "df1 = yays.loc[yays_i]\n",
    "\n",
    "nays = analysed_users[(analysed_users.follows_sg == False) & (analysed_users.follows_professional_sg == False)]\n",
    "nays.reset_index(inplace=True)\n",
    "nays_i = np.random.choice(nays.shape[0],2000)\n",
    "df2 = nays.loc[nays_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users['is_support'] = (analysed_users['follows_sg'] == True) | (analysed_users['follows_professional_sg'] == True)\n",
    "analysed_users.loc[(analysed_users['compound_np'] != 0) & (analysed_users['compound'] != 0)][['compound_np','compound']].hist(bins=25, by=analysed_users['is_support'],figsize=(15,5), sharex=True, sharey=True)\n",
    "analysed_users[['pos_np','pos']].hist(bins=25, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n",
    "analysed_users[['neg_np','neg']].hist(bins=25, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n",
    "analysed_users[['neu_np','neu']].hist(bins=25, by=analysed_users['is_support'], figsize=(15,6), sharex=True, sharey=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(analysed_users.is_support, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['compound', 'pos', 'neg', 'neu']\n",
    "cols_np = ['compound_np', 'pos_np', 'neg_np', 'neu_np']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[analysed_users['is_support'] == True][cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users[analysed_users['is_support'] == False][cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[(analysed_users['is_support'] == True) & (analysed_users['compound_np'] !=0) & (analysed_users['compound'] !=0) ][['compound_np','compound']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysed_users.loc[(analysed_users['is_support'] == False) & (analysed_users['compound_np'] !=0) & (analysed_users['compound'] !=0) ][['compound_np','compound']].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
